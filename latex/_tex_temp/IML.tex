% ===========================================================
%  Sylabus: Wprowadzenie do machine learning (IML)
% ===========================================================
\documentclass[12pt, a4paper]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{mdframed}
\usepackage[colorlinks=true, linkcolor=red!70!black, urlcolor=red!70!black]{hyperref}
\usepackage{eso-pic}
\usepackage{tikz}

\definecolor{pjatkRed}{RGB}{180,0,0}
\definecolor{pjatkGray}{RGB}{80,80,80}
\definecolor{pjatkLightGray}{RGB}{245,245,245}
\definecolor{tableHeader}{RGB}{220,220,220}

\pagestyle{fancy}\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{\small\textcolor{pjatkGray}{PJATK -- Filia w Gdańsku \textbar\ Informatyka}}
\fancyhead[R]{\small\textcolor{pjatkGray}{Sylabus: IML}}
\fancyfoot[C]{\small\thepage}

\titleformat{\section}{\large\bfseries\color{pjatkRed}}{\thesection.}{0.5em}{}
  [\color{pjatkRed}\rule{\linewidth}{0.8pt}]
\setlist{noitemsep, topsep=3pt, parsep=2pt}

\newmdenv[linecolor=pjatkRed, linewidth=1.2pt, backgroundcolor=pjatkLightGray,
  innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=8pt,
  innerbottommargin=8pt, roundcorner=4pt]{infobox}

\begin{document}

\AddToShipoutPictureBG{%
  \begin{tikzpicture}[remember picture, overlay]
    \node[opacity=0.5] at (current page.center) {%
      \includegraphics[width=14cm]{C:/Users/adamu/WebstormProjects/pj-studies/latex/PJATK_pl_sygnet_transparent-eps-converted-to}%
    };
  \end{tikzpicture}%
}

\begin{center}
  \includegraphics[height=2cm]{C:/Users/adamu/WebstormProjects/pj-studies/latex/PJATK_pl_poziom_1}\\[0.8cm]
  {\LARGE\bfseries\color{pjatkRed} SYLABUS PRZEDMIOTU}\\[0.8cm]
\end{center}

\begin{infobox}
\begin{tabularx}{\textwidth}{@{}lX@{}}
  \textbf{Nazwa przedmiotu:}  & {\bfseries Wprowadzenie do machine learning} \\[3pt]
  \textbf{Kod przedmiotu:}    & IML \\[3pt]
  \textbf{Kierunek / Profil:} & Informatyka / praktyczny \\[3pt]
  \textbf{Tryb studiów:}      & niestacjonarny \\[3pt]
  \textbf{Rok / Semestr:}     & 3 / 6 \\[3pt]
  \textbf{Charakter:}         & obowiązkowy \\[3pt]
  \textbf{Odpowiedzialny:}    & dr inż. Paweł Syty \\[3pt]
  \textbf{Wersja z dnia:}     & 19.02.2026 \\
\end{tabularx}
\end{infobox}

\vspace{1cm}

\section{Godziny zajęć i punkty ECTS}

\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.4cm}
                |>{\centering\arraybackslash}p{2.4cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{1.4cm}|}
\hline
\rowcolor{tableHeader}
\textbf{Wykłady} & \textbf{Ćwiczenia} & \textbf{Laboratorium} &
\textbf{Z prowadzącym} & \textbf{Praca własna} & \textbf{Łącznie} & \textbf{ECTS} \\
\hline
30 h & --- & 30 h & 60 h & 65 h & 125 h & \textbf{5} \\
\hline
\end{tabular}
\end{center}

\section{Forma zajęć}

\begin{tabular}{ll}
  \hline
  \textbf{Forma zajęć} & \textbf{Sposób zaliczenia} \\
  \hline
  Laboratorium & Zaliczenie z oceną \\
  Wykład & Egzamin z oceną \\
  \hline
\end{tabular}

\section{Cel dydaktyczny}

Celem przedmiotu jest zaznajomienie studentów z podstawowymi zagadnieniami uczenia maszynowego (w tym elementami uczenia głębokiego), głównie z wykorzystaniem sieci neuronowych (w tym sieci splotowych), a także z metodami programowania wybranych metod oraz praktycznym wykorzystaniem gotowych narzędzi.

\section{Treści programowe}

\begin{enumerate}
  \item 1.  Historia i definicja uczenia maszynowego. Omówienie zastosowań uczenia maszynowego. Podział metod uczenia maszynowego. Rola danych i ich jakości w uczeniu maszynowym. Przygotowywanie danych do procesu uczenia. Wstęp do języka Python.
  \item 2.  Wiedza niedoskonała w uczeniu maszynowym. Metody radzenia sobie z niedoskonałością wiedzy. Wnioskowanie bayesowskie. Logika rozmyta.
  \item 3. Podstawy biologiczne sztucznych sieci neuronowych. Układ nerwowy zwierząt i człowieka –  podział i funkcje. Odbiór i przetwarzanie bodźców przez mózg. Neuron – budowa, systematyka. Przejawy życiowe neuronów. Pamięć.  Dyskusja możliwości i ograniczeń związanych z odwzorowywaniem układów biologicznych w postaci sztucznych systemów.
  \item 4.  Historia i podstawy sieci neuronowych. Podstawowy model komórki nerwowej – perceptron prosty i jego właściwości. Perceptron prosty jako uogólnienie regresji liniowej. Podstawowe metody uczenia perceptronu. Ograniczenia pojedynczego perceptronu. Łączenie perceptronów w większe struktury. Podstawowa klasyfikacja architektur sztucznych sieci neuronowych. Wstępna klasyfikacja zastosowań sieci neuronowych. Cechy sztucznych sieci neuronowych predestynujące je do zastosowań we współczesnym świecie.
  \item 5.  Sieci jednokierunkowe jednowarstwowe. Budowa, metody uczenia, zastosowania, ograniczenia. Mapa wag.  Hiperparametry. Metryki. Kodowanie danych.
  \item 6. Sieci jednokierunkowe wielowarstwowe. Budowa, metody uczenia, zastosowania, ograniczenia. Więcej o metodach uczenia sieci – metoda propagacji wstecznej, metoda momentum (w tym metoda Nesterova). Omówienie wybranych optymalizatorów (SGD, RMSprop, Adam). Inicjalizacja modelu. Funkcje aktywacji.
  \item 7.  Zdolność uogólniania sieci neuronowej. Miary zdolności uogólniania. Twierdzenie Kołmogorowa. Zbiór uczący (treningowy), walidujący i testowy. Przeuczenie i niedouczenie sieci. Metody regularyzacji. Dobór optymalnej architektury sieci. Proces redukcji wymiaru sieci. Warstwy Dropout.
  \item 8. Sieci splotowe. Budowa, metody uczenia, zastosowania, ograniczenia. Operacja splotu (konwolucja). Warstwy łączące (pooling). Filtry.  Biblioteka OpenCV. Metody i architektury sieci neuronowych do rozpoznawania obrazów. Sieci typu Lenet, VGGNet. Klasyfikacja wieloetykietowa. Augmentacja danych.
  \item 9. Sieci autoasocjacyjne. Transfer learning. Walidacja krzyżowa. Elementy wyjaśnialnej sztucznej inteligencji.
  \item 10. Sieci rekurencyjne. Budowa, metody uczenia, zastosowania, ograniczenia. Pamięci asocjacyjne. Komórki LSTM i GRU.
  \item 11. Strategie gier dwuosobowych. Algorytm MINIMAX.  Funkcja heurystyczna. Przycinanie alfa-beta. Idea self-play.
  \item 12. Automaty komórkowe ze szczególnym uwzględnieniem ich zastosowania w uczeniu maszynowym.
  \item 13. Pozostałe metody uczenia maszynowego: k-najbliższych sąsiadów, maszyna wektorów nośnych (SVM), drzewo decyzyjne, las losowy, algorytmy ewolucyjne, liniowe modele mieszane. Metody zespołowe (ensemble).
  \item 14. Elementy uczenia nienadzorowanego. Analiza skupień. Algorytm centroidów (k-means). Analiza szeregów czasowych. Algorytm k-shape i DTW (Dynamic Time Warping).
  \item 15. Elementy języka Prolog. Zapis predykatów. Wnioskowanie wstecz i w przód.
  \item // A. lista dotychczas zaproponowanych metod dydaktycznych; można zaproponować inne.
  \item Wykład:
  \item wykład
  \item wykład konwersatoryjny (z elementami dyskusji)
  \item wykład z prezentacją multimedialną
  \item wykład z prezentacją oprogramowania
  \item warsztaty
  \item Ćwiczenia / Laboratorium/Lektorat:
  \item analiza tekstów z dyskusją
  \item metoda projektów (projekt praktyczny)
  \item praca w grupach
  \item dyskusja
  \item rozwiązywanie zadań
  \item burza mózgów
  \item mind map
  \item puzzle learning
  \item studia przypadków z bazy studiów przypadków opracowanych przez firmy MŚP lub będące efektem staży
  \item praca grupowa nad projektem z wykorzystaniem nowoczesnych technik informatycznych
  \item warsztaty
  \item // B. lista dotychczas zaproponowanych metod weryfikacji; można zaproponować inne.
  \item sprawdziany wstępne „wejściówki”
  \item kolokwium
  \item kolokwium końcowe
  \item egzamin pisemny
  \item egzamin pisemny - test wyboru
  \item egzamin pisemny - tekst z lukami
  \item egzamin pisemny z zadaniami problemowymi
  \item egzamin pisemny ze studium przypadku
  \item egzamin ustny
  \item końcowe sprawozdanie z pracy w zespole
  \item prezentacja samodzielnej pracy semestralnej
  \item prezentacja elementu zespołowej pracy semestralnej
  \item prezentacja projektu i dokumentacji
  \item prezentacja mini-projektu
  \item obrona projektu
  \item rezultaty gry strategicznej
  \item ocena pracy podczas ćwiczenia
  \item raport z wykonanego zadania
  \item ocena sporządzonego dokumentu
  \item ocena sporządzonego oprogramowania
  \item wskazanie źródeł użytych materiałów
  \item kwestionariusz wywiadu
  \item sprawozdanie z rozmowy
  \item zapisanie na ścieżkę certyfikacyjną
  \item //C. ECTS sposób obliczania
  \item 1 punkt ECTS przyznawany jest za 25-30 godzin pracy studenta. W obliczanie punktów ECTS włącza się:
  \item liczbę godzin poszczególnych przedmiotów w danym semestrze;
  \item czas, jaki student poświęcił na indywidualną naukę (w tym przygotowanie do zajęć, zbieranie materiałów czy pisanie prac zaliczeniowych);
  \item czas, jaki student poświęcił na przygotowanie do egzaminu i zaliczenie danego przedmiotu;
  \item liczbę godzin praktyk studenckich.
\end{enumerate}

\section{Efekty kształcenia}

\subsection*{Wiedza}
\begin{itemize}
  \item Student zna i rozumie zastosowania wybranych narzędzi uczenia maszynowego
  \item Student wie, że jakość danych ma kluczowe znaczenie w przypadku uczenia maszynowego
  \item Student zna i rozumie metody przechowywania danych dla uczenia maszynowego
  \item Student zna i rozumie zaawansowane pojęcia z zakresu uczenia maszynowego oraz sposoby ich wykorzystania w sytuacjach praktycznych.
\end{itemize}

\subsection*{Umiejętności}
\begin{itemize}
  \item Student potrafi  wybrać odpowiednie narzędzie do rozwiązania problemu zaistniałego w przedsiębiorstwie, a wymagającego użycia uczenia maszynowego
  \item Student potrafi  poprawnie przygotować dane i stworzyć na ich podstawie zbiory uczące, walidujące i testowe
  \item Student potrafi dobrać właściwe parametry wejściowe, by zoptymalizować działanie wybranych algorytmów.
  \item Student potrafi przeprowadzić analizę otrzymanych wyników
  \item Student potrafi zastosować narzędzia uczenia maszynowego w sytuacjach praktycznych.
\end{itemize}

\subsection*{Kompetencje społeczne}
\begin{itemize}
  \item Student jest gotów do ciągłego podnoszenia swoich kompetencji zawodowych, osobistych i społecznych oraz zna możliwości dokształcania się przez całe życie
\end{itemize}

\section{Kryteria oceny}

\begin{itemize}
  \item Ćwiczenia / Laboratorium/Lektorat:
  \item rozwiązywanie zadań
  \item studia przypadków z bazy studiów przypadków opracowanych przez firmy MŚP lub będące efektem staży
  \item warsztaty
  \item Kryteria oceny
  \item Ocena praktycznego zastosowania kwestii omawianych na wykładach. Studenci otrzymują zadania programistyczne do wykonania podczas zajęć (do zdobycia maks. 40 punktów, z gradacją 0.5 p.)
\end{itemize}

\section{Metody dydaktyczne}

Wykład, laboratoria, praca własna studenta.

\section{Literatura}

\textbf{Podstawowa:}
\begin{itemize}
  \item Daniel T. Larose „Metody i modele eksploracji danych”, PWN 2022
  \item Aurélien Géron, „Uczenie maszynowe z użyciem Scikit-Learn i TensorFlow”, Helion 2020
  \item Robert Johansson „Matematyczny Python. Obliczenia naukowe i analiza danych z użyciem NumPy, SciPy i Matplotlib”, Helion 2021
  \item Sebastian Raschka, Vahid Mirjalili „Python. Machine learning i deep learning. Biblioteki scikit-learn i TensorFlow 2”, Helion 2021
  \item Aileen Nielsen, „Szeregi czasowe. Praktyczna analiza i predykcja z wykorzystaniem statystyki i uczenia maszynowego”, Helion 2020
\end{itemize}

\textbf{Uzupełniająca:}
\begin{itemize}
  \item Joel Grus, „Data science od podstaw. Analiza danych w Pythonie”, Helion 2020
  \item Dokumentacja pakietów Keras i Tensorflow
\end{itemize}

\end{document}
