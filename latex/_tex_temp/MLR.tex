% ===========================================================
%  Sylabus: Machine learning ()
% ===========================================================
\documentclass[12pt, a4paper]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{mdframed}
\usepackage[colorlinks=true, linkcolor=red!70!black, urlcolor=red!70!black]{hyperref}
\usepackage{eso-pic}
\usepackage{tikz}

\definecolor{pjatkRed}{RGB}{180,0,0}
\definecolor{pjatkGray}{RGB}{80,80,80}
\definecolor{pjatkLightGray}{RGB}{245,245,245}
\definecolor{tableHeader}{RGB}{220,220,220}

\pagestyle{fancy}\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{\small\textcolor{pjatkGray}{PJATK -- Filia w Gdańsku \textbar\ Informatyka}}
\fancyhead[R]{\small\textcolor{pjatkGray}{Sylabus: }}
\fancyfoot[C]{\small\thepage}

\titleformat{\section}{\large\bfseries\color{pjatkRed}}{\thesection.}{0.5em}{}
  [\color{pjatkRed}\rule{\linewidth}{0.8pt}]
\setlist{noitemsep, topsep=3pt, parsep=2pt}

\newmdenv[linecolor=pjatkRed, linewidth=1.2pt, backgroundcolor=pjatkLightGray,
  innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=8pt,
  innerbottommargin=8pt, roundcorner=4pt]{infobox}

\begin{document}

\AddToShipoutPictureBG{%
  \begin{tikzpicture}[remember picture, overlay]
    \node[opacity=0.5] at (current page.center) {%
      \includegraphics[width=14cm]{C:/Users/adamu/WebstormProjects/pj-studies/latex/PJATK_pl_sygnet_transparent-eps-converted-to}%
    };
  \end{tikzpicture}%
}

\begin{center}
  \includegraphics[height=2cm]{C:/Users/adamu/WebstormProjects/pj-studies/latex/PJATK_pl_poziom_1}\\[0.8cm]
  {\LARGE\bfseries\color{pjatkRed} SYLABUS PRZEDMIOTU}\\[0.8cm]
\end{center}

\begin{infobox}
\begin{tabularx}{\textwidth}{@{}lX@{}}
  \textbf{Nazwa przedmiotu:}  & {\bfseries Machine learning} \\[3pt]
  \textbf{Kod przedmiotu:}    &  \\[3pt]
  \textbf{Kierunek / Profil:} & Informatyka / praktyczny \\[3pt]
  \textbf{Tryb studiów:}      & stacjonarny \\[3pt]
  \textbf{Rok / Semestr:}     & 3 / 5 \\[3pt]
  \textbf{Charakter:}         & obieralny \\[3pt]
  \textbf{Odpowiedzialny:}    & dr inż. Paweł Syty \\[3pt]
  \textbf{Wersja z dnia:}     & 19.02.2026 \\
\end{tabularx}
\end{infobox}

\vspace{1cm}

\section{Godziny zajęć i punkty ECTS}

\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{2.4cm}
                |>{\centering\arraybackslash}p{2.4cm}
                |>{\centering\arraybackslash}p{2.0cm}
                |>{\centering\arraybackslash}p{1.4cm}|}
\hline
\rowcolor{tableHeader}
\textbf{Wykłady} & \textbf{Ćwiczenia} & \textbf{Laboratorium} &
\textbf{Z prowadzącym} & \textbf{Praca własna} & \textbf{Łącznie} & \textbf{ECTS} \\
\hline
30 h & 30 h & --- & 60 h & 40 h & 100 h & \textbf{4} \\
\hline
\end{tabular}
\end{center}

\section{Forma zajęć}

\begin{tabular}{ll}
  \hline
  \textbf{Forma zajęć} & \textbf{Sposób zaliczenia} \\
  \hline
  Laboratorium & Zaliczenie z oceną \\
  Wykład & Nieoceniany \\
  \hline
\end{tabular}

\section{Cel dydaktyczny}

Celem przedmiotu jest zaznajomienie studentów z wybranymi zagadnieniami uczenia maszynowego (w tym elementami uczenia głębokiego), głównie z wykorzystaniem sieci neuronowych (w tym sieci splotowych), a także z metodami programowania wybranych metod oraz praktycznym wykorzystaniem gotowych narzędzi i bibliotek.

\section{Treści programowe}

\begin{enumerate}
  \item 1.  Historia i definicja uczenia maszynowego. Omówienie zastosowań uczenia maszynowego. Podział metod uczenia maszynowego. Rola danych i ich jakości w uczeniu maszynowym. Przygotowywanie danych do procesu uczenia. Wstęp do języka Python.
  \item 2.  Wiedza niedoskonała w uczeniu maszynowym. Metody radzenia sobie z niedoskonałością wiedzy. Wnioskowanie bayesowskie. Logika rozmyta.
  \item 3. Podstawy biologiczne sztucznych sieci neuronowych. Układ nerwowy zwierząt i człowieka –  podział i funkcje. Odbiór i przetwarzanie bodźców przez mózg. Neuron – budowa, systematyka. Przejawy życiowe neuronów. Pamięć.  Dyskusja możliwości i ograniczeń związanych z odwzorowywaniem układów biologicznych w postaci sztucznych systemów.
  \item 4.  Historia i podstawy sieci neuronowych. Podstawowy model komórki nerwowej – perceptron prosty i jego właściwości. Perceptron prosty jako uogólnienie regresji liniowej. Podstawowe metody uczenia perceptronu. Ograniczenia pojedynczego perceptronu. Łączenie perceptronów w większe struktury. Podstawowa klasyfikacja architektur sztucznych sieci neuronowych. Wstępna klasyfikacja zastosowań sieci neuronowych. Cechy sztucznych sieci neuronowych predestynujące je do zastosowań we współczesnym świecie.
  \item 5.  Sieci jednokierunkowe jednowarstwowe. Budowa, metody uczenia, zastosowania, ograniczenia. Mapa wag.  Hiperparametry. Metryki. Kodowanie danych.
  \item 6. Sieci jednokierunkowe wielowarstwowe. Budowa, metody uczenia, zastosowania, ograniczenia. Więcej o metodach uczenia sieci – metoda propagacji wstecznej, metoda momentum (w tym metoda Nesterova). Omówienie wybranych optymalizatorów (SGD, RMSprop, Adam). Inicjalizacja modelu. Funkcje aktywacji.
  \item 7.  Zdolność uogólniania sieci neuronowej. Miary zdolności uogólniania. Twierdzenie Kołmogorowa. Zbiór uczący (treningowy), walidujący i testowy. Przeuczenie i niedouczenie sieci. Metody regularyzacji. Dobór optymalnej architektury sieci. Proces redukcji wymiaru sieci. Warstwy Dropout.
  \item 8. Sieci splotowe. Budowa, metody uczenia, zastosowania, ograniczenia. Operacja splotu (konwolucja). Warstwy łączące (pooling). Filtry.  Biblioteka OpenCV. Metody i architektury sieci neuronowych do rozpoznawania obrazów. Sieci typu Lenet, VGGNet. Klasyfikacja wieloetykietowa. Augmentacja danych.
  \item 9. Sieci autoasocjacyjne. Transfer learning. Walidacja krzyżowa. Elementy wyjaśnialnej sztucznej inteligencji.
  \item 10. Sieci rekurencyjne. Budowa, metody uczenia, zastosowania, ograniczenia. Pamięci asocjacyjne. Komórki LSTM i GRU.
  \item 11. Strategie gier dwuosobowych. Algorytm MINIMAX.  Funkcja heurystyczna. Przycinanie alfa-beta. Idea self-play.
  \item 12. Automaty komórkowe ze szczególnym uwzględnieniem ich zastosowania w uczeniu maszynowym.
  \item 13. Pozostałe metody uczenia maszynowego: k-najbliższych sąsiadów, maszyna wektorów nośnych (SVM), drzewo decyzyjne, las losowy, algorytmy ewolucyjne, liniowe modele mieszane. Metody zespołowe (ensemble).
  \item 14. Elementy uczenia nienadzorowanego. Analiza skupień. Algorytm centroidów (k-means). Analiza szeregów czasowych. Algorytm k-shape i DTW (Dynamic Time Warping).
  \item 15. Elementy języka Prolog. Zapis predykatów. Wnioskowanie wstecz i w przód.
\end{enumerate}

\section{Efekty kształcenia}

\subsection*{Wiedza}
\begin{itemize}
  \item Student zna i rozumie podstawowe zastosowania wybranych narzędzi uczenia maszynowego
  \item Student wie, że jakość danych ma kluczowe znaczenie w przypadku uczenia maszynowego
  \item Student zna i rozumie metody przechowywania danych dla uczenia maszynowego
\end{itemize}

\subsection*{Umiejętności}
\begin{itemize}
  \item Student potrafi  wybrać odpowiednie narzędzie do rozwiązania problemu zaistniałego w przedsiębiorstwie, a wymagającego użycia uczenia maszynowego
  \item Student potrafi  poprawnie przygotować dane i stworzyć na ich podstawie zbiory uczące, walidujące i testowe
  \item Student potrafi dobrać właściwe parametry wejściowe, by zoptymalizować działanie wybranych algorytmów.
  \item Student potrafi przeprowadzić analizę otrzymanych wyników
\end{itemize}

\subsection*{Kompetencje społeczne}
\begin{itemize}
  \item Student jest gotów do ciągłego podnoszenia swoich kompetencji zawodowych, osobistych i społecznych oraz zna możliwości dokształcania się przez całe życie
\end{itemize}

\section{Kryteria oceny}

\begin{itemize}
  \item Ćwiczenia / Laboratorium/Lektorat:
  \item rozwiązywanie zadań
  \item studia przypadków z bazy studiów przypadków opracowanych przez firmy MŚP lub będące efektem staży
  \item warsztaty
  \item Kryteria oceny
  \item Ocena praktycznego zastosowania zagadnień omawianych na wykładach. Studenci otrzymują zadania programistyczne do wykonania podczas zajęć (do zdobycia maks. 40 punktów, z gradacją 0.5 p.) oraz zadanie indywidualne (do zdobycia maks. 10 punktów). Przedmiot zalicza otrzymanie w sumie co najmniej 25 punktów.
\end{itemize}

\section{Metody dydaktyczne}

Wykład, laboratoria, praca własna studenta.

\section{Literatura}

\textbf{Podstawowa:}
\begin{itemize}
  \item Daniel T. Larose „Metody i modele eksploracji danych”, PWN 2022
  \item Aurélien Géron, „Uczenie maszynowe z użyciem Scikit-Learn i TensorFlow”, Helion 2020
  \item Robert Johansson „Matematyczny Python. Obliczenia naukowe i analiza danych z użyciem NumPy, SciPy i Matplotlib”, Helion 2021
  \item Sebastian Raschka, Vahid Mirjalili „Python. Machine learning i deep learning. Biblioteki scikit-learn i TensorFlow 2”, Helion 2021
  \item Aileen Nielsen, „Szeregi czasowe. Praktyczna analiza i predykcja z wykorzystaniem statystyki i uczenia maszynowego”, Helion 2020
\end{itemize}

\textbf{Uzupełniająca:}
\begin{itemize}
  \item Joel Grus, „Data science od podstaw. Analiza danych w Pythonie”, Helion 2020
  \item Dokumentacja pakietów Keras i Tensorflow
\end{itemize}

\end{document}
